{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "This is a simple tutorial showing how to use spDB. This example makes use of the Fiqa Beir dataset. You can find more information about the Beir datasets [here](https://github.com/beir-cellar/beir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment\n",
    "\n",
    "First, we will set up the environment by importing the required libraries and appending the paths needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load in spDB from the local directory\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(current_dir + \"/../\")\n",
    "sys.path.append(current_dir + \"/../tests/integration/\")\n",
    "\n",
    "from spdb.spdb import spDB, load_db\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "# Load in the Fiqa test data\n",
    "vectors, text, queries, _ = helpers.fiqa_test_data()\n",
    "with open(current_dir + \"/../tests/data/fiqa_queries_text.pickle\", \"rb\") as f:\n",
    "    query_text = pickle.load(f)\n",
    "\n",
    "print (len(vectors))\n",
    "print (type(vectors[0][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the spDB object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the spDB\n",
    "db_name = \"fiqa_test\"\n",
    "db = spDB(db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the spDB\n",
    "\n",
    "This section is not necessary to run, it just shows how to load in an spDB object that has been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "<faiss.swigfaiss_avx2.IndexPreTransform; proxy of <Swig Object of type 'faiss::IndexPreTransform *' at 0x7fe0f8aab1b0> >\n",
      "1576.8234666666667\n",
      "Fitted parameters: C = 4219994.86512343, b = 39.51947796057294\n"
     ]
    }
   ],
   "source": [
    "# Optional: Load in the spDB object\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "db_name = \"fiqa_test_1\"\n",
    "db = load_db(db_name)\n",
    "print (db.faiss_index.ntotal)\n",
    "print (db.faiss_index)\n",
    "print (47304704/(db.faiss_index.ntotal))\n",
    "\n",
    "# PQ64\n",
    "#vectors = np.array([60000, 120000, 240000, 360000, 600000])\n",
    "#memory_per_vector = np.array([142.1, 106.2, 89.1, 83.4, 78.84])\n",
    "\n",
    "#PQ32\n",
    "vectors = np.array([60000, 120000, 180000, 240000, 360000, 600000])\n",
    "memory_per_vector = np.array([110.1, 74.2, 62.8, 57.1, 51.4, 46.8])\n",
    "\n",
    "#PQ128\n",
    "#vectors = np.array([60000, 120000, 180000, 240000, 360000, 600000])\n",
    "#memory_per_vector = np.array([206.1, 170.2, 158.8, 153.1, 147.4, 142.8])\n",
    "\n",
    "vectors = np.array([60000, 120000, 180000, 240000, 360000, 600000])\n",
    "memory_per_vector = np.array([8525840, 12744704, 17064704, 21384704, 30024704, 47304704])\n",
    "\n",
    "def model(n, C, b):\n",
    "    return C / n + b\n",
    "\n",
    "params, params_covariance = curve_fit(model, vectors, memory_per_vector)\n",
    "\n",
    "C, b = params\n",
    "print(f\"Fitted parameters: C = {C}, b = {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<faiss.swigfaiss_avx2.IndexPreTransform; proxy of <Swig Object of type 'faiss::IndexPreTransform *' at 0x7fe0f8a88d50> >\n"
     ]
    }
   ],
   "source": [
    "print (db.faiss_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "def generate_random_vectors_with_text(N, D):\n",
    "    random_vectors = np.random.rand(N, D).astype(np.float32) \n",
    "    random_text = [''.join(random.choices(string.ascii_lowercase, k=D)) for _ in range(N)]\n",
    "    return random_vectors, random_text\n",
    "\n",
    "# Specify the number of random vectors (N) and the dimensionality (D)\n",
    "N = 30000  # Number of random vectors\n",
    "D = 2048  # Dimensionality of each vector\n",
    "\n",
    "# Generate N random vectors with D dimensions and random text strings\n",
    "random_vectors, random_text = generate_random_vectors_with_text(N, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7785779.197298177\n",
      "15945275796.066666\n"
     ]
    }
   ],
   "source": [
    "def predict_memory(n):\n",
    "    return model(n, C, b)\n",
    "\n",
    "def predict_full_memory(n, C, b):\n",
    "    return C + (b * n)\n",
    "\n",
    "print (predict_memory(2048))\n",
    "print (predict_full_memory(2048, C, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add data to the spDB\n",
    "\n",
    "The data must be a list of tuples, where each tuple contains `(vector, metadata)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(570000, 600000)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the data to the spDB\n",
    "add_data = [(random_vectors[i], {\"text\": random_text[i]}) for i in range(len(random_vectors))]\n",
    "db.add(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "# Get info\n",
    "print(db.vector_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the faiss index\n",
    "\n",
    "For this example, we are using PCA 256, compressed vector bytes of 32, and omitting OPQ\n",
    "\n",
    "For more information on these parameters, you can visit the Github Wiki [here](https://github.com/SuperpoweredAI/spDB/wiki/Tunable-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the spDB\n",
    "db.train(True, pca_dimension=256, compressed_vector_bytes=32, omit_opq=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the trained index\n",
    "\n",
    "Make a test query using the `db.query()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a test query\n",
    "results = db.query(queries[0])\n",
    "print (\"Query text:\", query_text[0])\n",
    "print (\"\")\n",
    "print (results[\"metadata\"][0][\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6493f77fe247bf2d19f0ba28dd5345ab8e8eb3b6587168c5c28be0d535e3568d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
